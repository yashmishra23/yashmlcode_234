{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f459d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMPORT LIBRARIES\n",
    "# ======================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f693b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 2. LOAD DATASET\n",
    "# ======================================================\n",
    "train = pd.read_csv(\"/kaggle/input/yashdataset02/train (1).csv\")\n",
    "test  = pd.read_csv(\"/kaggle/input/yashdataset02/test (1).csv\")\n",
    "\n",
    "TARGET = \"Status\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980eb34",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee1d810",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33218d75",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ===================== BASIC CLEANING =====================\n",
    "train = train.drop_duplicates()\n",
    "test  = test.drop_duplicates()\n",
    "# ======================================================\n",
    "# 3. DATA CLEANING & PREPROCESSING\n",
    "# ======================================================\n",
    "# Drop duplicates\n",
    "train.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop high-cardinality / irrelevant columns\n",
    "# drop_cols = [\"Name\", \"Ticket\", \"Cabin\"]\n",
    "# train.drop(columns=drop_cols, inplace=True, errors=\"ignore\")\n",
    "# test.drop(columns=drop_cols, inplace=True, errors=\"ignore\")\n",
    "\n",
    "\n",
    "# Separate numerical & categorical columns\n",
    "num_cols = train.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "cat_cols = train.select_dtypes(include=[\"object\"]).columns.drop(TARGET)\n",
    "\n",
    "# Handle missing values\n",
    "train[num_cols] = train[num_cols].fillna(train[num_cols].median())\n",
    "test[num_cols]  = test[num_cols].fillna(test[num_cols].median())\n",
    "\n",
    "train[cat_cols] = train[cat_cols].fillna(train[cat_cols].mode().iloc[0])\n",
    "test[cat_cols]  = test[cat_cols].fillna(test[cat_cols].mode().iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47392a06",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 4. DATA VISUALIZATION & OUTLIER ANALYSIS\n",
    "# ======================================================\n",
    "train[num_cols].hist(figsize=(12,8))\n",
    "plt.suptitle(\"Feature Distributions\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(data=train[num_cols])\n",
    "plt.title(\"Outlier Analysis\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161b9bd1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 5. ENCODING CATEGORICAL VARIABLES\n",
    "# ======================================================\n",
    "# for col in cat_cols:\n",
    "#     le = LabelEncoder()\n",
    "#     train[col] = le.fit_transform(train[col])\n",
    "#     test[col]  = le.transform(test[col])\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in cat_cols:\n",
    "    # force everything to string\n",
    "    train[col] = train[col].astype(str)\n",
    "    test[col]  = test[col].astype(str)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    combined = pd.concat([train[col], test[col]], axis=0)\n",
    "    le.fit(combined)\n",
    "    \n",
    "    train[col] = le.transform(train[col])\n",
    "    test[col]  = le.transform(test[col])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5063aa45",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 7. FEATURE SCALING\n",
    "# ======================================================\n",
    "X = train.drop(TARGET, axis=1)\n",
    "y = train[TARGET]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "test_scaled = scaler.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a327a67f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 8. TRAINâ€“TEST SPLIT\n",
    "# ======================================================\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e87749",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 9. MODEL TRAINING\n",
    "# ======================================================\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"SVM\": SVC(probability=True)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1ac842",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 10. MODEL EVALUATION\n",
    "# ======================================================\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "\n",
    "    print(f\"\\nðŸ”¹ {name}\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_val, preds))\n",
    "    print(\"Precision:\", precision_score(y_val, preds, average=\"weighted\"))\n",
    "    print(\"Recall   :\", recall_score(y_val, preds, average=\"weighted\"))\n",
    "    print(\"F1 Score :\", f1_score(y_val, preds, average=\"weighted\"))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, preds))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_val, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa4349",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 11. HYPER-PARAMETER TUNING (RANDOM FOREST)\n",
    "# ======================================================\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"f1_weighted\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "best_rf = grid.best_estimator_\n",
    "\n",
    "print(\"\\nBest Random Forest Parameters:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430fd6f6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 12. FINAL MODEL EVALUATION\n",
    "# ======================================================\n",
    "final_preds = best_rf.predict(X_val)\n",
    "print(\"\\nFinal Tuned Random Forest Performance\")\n",
    "print(classification_report(y_val, final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c3916",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "proba = model.predict_proba(test)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"Status_C\":  proba[:, 0],\n",
    "    \"Status_CL\": proba[:, 1],\n",
    "    \"Status_D\":  proba[:, 2]\n",
    "})\n",
    "\n",
    "# Save file\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"submission.csv generated successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
