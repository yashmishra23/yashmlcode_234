{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31234,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:11:11.062785Z","iopub.execute_input":"2025-12-18T17:11:11.063106Z","iopub.status.idle":"2025-12-18T17:11:11.069146Z","shell.execute_reply.started":"2025-12-18T17:11:11.063080Z","shell.execute_reply":"2025-12-18T17:11:11.068067Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# 1. IMPORT LIBRARIES\n# ======================================================\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score,\n    f1_score, confusion_matrix, classification_report\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:11:11.070840Z","iopub.execute_input":"2025-12-18T17:11:11.071153Z","iopub.status.idle":"2025-12-18T17:11:11.092083Z","shell.execute_reply.started":"2025-12-18T17:11:11.071125Z","shell.execute_reply":"2025-12-18T17:11:11.091085Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# ======================================================\n# 2. LOAD DATASET\n# ======================================================\ntrain = pd.read_csv(\"/kaggle/input/yashdataset02/train (1).csv\")\ntest  = pd.read_csv(\"/kaggle/input/yashdataset02/test (1).csv\")\n\nTARGET = \"Status\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:11:11.093328Z","iopub.execute_input":"2025-12-18T17:11:11.093670Z","iopub.status.idle":"2025-12-18T17:11:11.125414Z","shell.execute_reply.started":"2025-12-18T17:11:11.093632Z","shell.execute_reply":"2025-12-18T17:11:11.123853Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/799768907.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 2. LOAD DATASET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ======================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/yashdataset02/train (1).csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/yashdataset02/test (1).csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/yashdataset02/train (1).csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/yashdataset02/train (1).csv'","output_type":"error"}],"execution_count":51},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:11:11.126067Z","iopub.status.idle":"2025-12-18T17:11:11.126407Z","shell.execute_reply.started":"2025-12-18T17:11:11.126219Z","shell.execute_reply":"2025-12-18T17:11:11.126235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:11:11.128542Z","iopub.status.idle":"2025-12-18T17:11:11.129262Z","shell.execute_reply.started":"2025-12-18T17:11:11.129051Z","shell.execute_reply":"2025-12-18T17:11:11.129072Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================== BASIC CLEANING =====================\ntrain = train.drop_duplicates()\ntest  = test.drop_duplicates()\n# ======================================================\n# 3. DATA CLEANING & PREPROCESSING\n# ======================================================\n# Drop duplicates\ntrain.drop_duplicates(inplace=True)\n\n# Drop high-cardinality / irrelevant columns\n# drop_cols = [\"Name\", \"Ticket\", \"Cabin\"]\n# train.drop(columns=drop_cols, inplace=True, errors=\"ignore\")\n# test.drop(columns=drop_cols, inplace=True, errors=\"ignore\")\n\n\n# Separate numerical & categorical columns\nnum_cols = train.select_dtypes(include=[\"int64\",\"float64\"]).columns\ncat_cols = train.select_dtypes(include=[\"object\"]).columns.drop(TARGET)\n\n# Handle missing values\ntrain[num_cols] = train[num_cols].fillna(train[num_cols].median())\ntest[num_cols]  = test[num_cols].fillna(test[num_cols].median())\n\ntrain[cat_cols] = train[cat_cols].fillna(train[cat_cols].mode().iloc[0])\ntest[cat_cols]  = test[cat_cols].fillna(test[cat_cols].mode().iloc[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:11:11.130721Z","iopub.status.idle":"2025-12-18T17:11:11.131148Z","shell.execute_reply.started":"2025-12-18T17:11:11.130924Z","shell.execute_reply":"2025-12-18T17:11:11.130959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ======================================================\n# 4. DATA VISUALIZATION & OUTLIER ANALYSIS\n# ======================================================\ntrain[num_cols].hist(figsize=(12,8))\nplt.suptitle(\"Feature Distributions\")\nplt.show()\n\nplt.figure(figsize=(10,5))\nsns.boxplot(data=train[num_cols])\nplt.title(\"Outlier Analysis\")\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:11:11.132473Z","iopub.status.idle":"2025-12-18T17:11:11.132811Z","shell.execute_reply.started":"2025-12-18T17:11:11.132662Z","shell.execute_reply":"2025-12-18T17:11:11.132681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ======================================================\n# 5. ENCODING CATEGORICAL VARIABLES\n# ======================================================\n# for col in cat_cols:\n#     le = LabelEncoder()\n#     train[col] = le.fit_transform(train[col])\n#     test[col]  = le.transform(test[col])\nfrom sklearn.preprocessing import LabelEncoder\n\nfor col in cat_cols:\n    # force everything to string\n    train[col] = train[col].astype(str)\n    test[col]  = test[col].astype(str)\n    \n    le = LabelEncoder()\n    combined = pd.concat([train[col], test[col]], axis=0)\n    le.fit(combined)\n    \n    train[col] = le.transform(train[col])\n    test[col]  = le.transform(test[col])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:11:11.134173Z","iopub.status.idle":"2025-12-18T17:11:11.134547Z","shell.execute_reply.started":"2025-12-18T17:11:11.134393Z","shell.execute_reply":"2025-12-18T17:11:11.134410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ======================================================\n# 7. FEATURE SCALING\n# ======================================================\nX = train.drop(TARGET, axis=1)\ny = train[TARGET]\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\ntest_scaled = scaler.transform(test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:11:11.136197Z","iopub.status.idle":"2025-12-18T17:11:11.136648Z","shell.execute_reply.started":"2025-12-18T17:11:11.136433Z","shell.execute_reply":"2025-12-18T17:11:11.136461Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ======================================================\n# 8. TRAINâ€“TEST SPLIT\n# ======================================================\nX_train, X_val, y_train, y_val = train_test_split(\n    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:11:11.225402Z","iopub.execute_input":"2025-12-18T17:11:11.225731Z","iopub.status.idle":"2025-12-18T17:11:11.248830Z","shell.execute_reply.started":"2025-12-18T17:11:11.225696Z","shell.execute_reply":"2025-12-18T17:11:11.247806Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# ======================================================\n# 9. MODEL TRAINING\n# ======================================================\nmodels = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n    \"KNN\": KNeighborsClassifier(),\n    \"Decision Tree\": DecisionTreeClassifier(),\n    \"Random Forest\": RandomForestClassifier(random_state=42),\n    \"Naive Bayes\": GaussianNB(),\n    \"SVM\": SVC(probability=True)\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:11:11.250800Z","iopub.execute_input":"2025-12-18T17:11:11.251089Z","iopub.status.idle":"2025-12-18T17:11:11.256963Z","shell.execute_reply.started":"2025-12-18T17:11:11.251062Z","shell.execute_reply":"2025-12-18T17:11:11.255708Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# ======================================================\n# 10. MODEL EVALUATION\n# ======================================================\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    preds = model.predict(X_val)\n\n    print(f\"\\nðŸ”¹ {name}\")\n    print(\"Accuracy :\", accuracy_score(y_val, preds))\n    print(\"Precision:\", precision_score(y_val, preds, average=\"weighted\"))\n    print(\"Recall   :\", recall_score(y_val, preds, average=\"weighted\"))\n    print(\"F1 Score :\", f1_score(y_val, preds, average=\"weighted\"))\n    print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, preds))\n    print(\"Classification Report:\\n\", classification_report(y_val, preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:11:11.258054Z","iopub.execute_input":"2025-12-18T17:11:11.258340Z","iopub.status.idle":"2025-12-18T17:11:41.235316Z","shell.execute_reply.started":"2025-12-18T17:11:11.258283Z","shell.execute_reply":"2025-12-18T17:11:41.233392Z"}},"outputs":[{"name":"stdout","text":"\nðŸ”¹ Logistic Regression\nAccuracy : 0.8293333333333334\nPrecision: 0.8080016808492109\nRecall   : 0.8293333333333334\nF1 Score : 0.8141413331884878\nConfusion Matrix:\n [[1901    0  122]\n [  56    0   18]\n [ 312    4  587]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           C       0.84      0.94      0.89      2023\n          CL       0.00      0.00      0.00        74\n           D       0.81      0.65      0.72       903\n\n    accuracy                           0.83      3000\n   macro avg       0.55      0.53      0.54      3000\nweighted avg       0.81      0.83      0.81      3000\n\n\nðŸ”¹ KNN\nAccuracy : 0.814\nPrecision: 0.7976168411017808\nRecall   : 0.814\nF1 Score : 0.8004454253086232\nConfusion Matrix:\n [[1865    3  155]\n [  55    2   17]\n [ 324    4  575]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           C       0.83      0.92      0.87      2023\n          CL       0.22      0.03      0.05        74\n           D       0.77      0.64      0.70       903\n\n    accuracy                           0.81      3000\n   macro avg       0.61      0.53      0.54      3000\nweighted avg       0.80      0.81      0.80      3000\n\n\nðŸ”¹ Decision Tree\nAccuracy : 0.7683333333333333\nPrecision: 0.7722315880647838\nRecall   : 0.7683333333333333\nF1 Score : 0.7702385242665764\nConfusion Matrix:\n [[1690   49  284]\n [  43   11   20]\n [ 270   29  604]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           C       0.84      0.84      0.84      2023\n          CL       0.12      0.15      0.13        74\n           D       0.67      0.67      0.67       903\n\n    accuracy                           0.77      3000\n   macro avg       0.54      0.55      0.55      3000\nweighted avg       0.77      0.77      0.77      3000\n\n\nðŸ”¹ Random Forest\nAccuracy : 0.846\nPrecision: 0.8358187417804296\nRecall   : 0.846\nF1 Score : 0.8334268210397845\nConfusion Matrix:\n [[1897    1  125]\n [  49    2   23]\n [ 263    1  639]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           C       0.86      0.94      0.90      2023\n          CL       0.50      0.03      0.05        74\n           D       0.81      0.71      0.76       903\n\n    accuracy                           0.85      3000\n   macro avg       0.72      0.56      0.57      3000\nweighted avg       0.84      0.85      0.83      3000\n\n\nðŸ”¹ Naive Bayes\nAccuracy : 0.32166666666666666\nPrecision: 0.845588369707478\nRecall   : 0.32166666666666666\nF1 Score : 0.44139296745594536\nConfusion Matrix:\n [[ 682 1301   40]\n [   5   69    0]\n [  91  598  214]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           C       0.88      0.34      0.49      2023\n          CL       0.04      0.93      0.07        74\n           D       0.84      0.24      0.37       903\n\n    accuracy                           0.32      3000\n   macro avg       0.58      0.50      0.31      3000\nweighted avg       0.85      0.32      0.44      3000\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3588088683.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ======================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":54},{"cell_type":"code","source":"# ======================================================\n# 11. HYPER-PARAMETER TUNING (RANDOM FOREST)\n# ======================================================\nparam_grid = {\n    \"n_estimators\": [100, 200],\n    \"max_depth\": [None, 10, 20],\n    \"min_samples_split\": [2, 5]\n}\n\ngrid = GridSearchCV(\n    RandomForestClassifier(random_state=42),\n    param_grid,\n    cv=3,\n    scoring=\"f1_weighted\",\n    n_jobs=-1\n)\n\ngrid.fit(X_train, y_train)\nbest_rf = grid.best_estimator_\n\nprint(\"\\nBest Random Forest Parameters:\", grid.best_params_)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:11:41.236841Z","iopub.status.idle":"2025-12-18T17:11:41.237287Z","shell.execute_reply.started":"2025-12-18T17:11:41.237054Z","shell.execute_reply":"2025-12-18T17:11:41.237091Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ======================================================\n# 12. FINAL MODEL EVALUATION\n# ======================================================\nfinal_preds = best_rf.predict(X_val)\nprint(\"\\nFinal Tuned Random Forest Performance\")\nprint(classification_report(y_val, final_preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:11:41.238586Z","iopub.status.idle":"2025-12-18T17:11:41.239681Z","shell.execute_reply.started":"2025-12-18T17:11:41.239432Z","shell.execute_reply":"2025-12-18T17:11:41.239460Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict class probabilities\nproba = model.predict_proba(test)\n\n# Create submission DataFrame\nsubmission = pd.DataFrame({\n    \"id\": test[\"id\"],\n    \"Status_C\":  proba[:, 0],\n    \"Status_CL\": proba[:, 1],\n    \"Status_D\":  proba[:, 2]\n})\n\n# Save file\nsubmission.to_csv(\"submission.csv\", index=False)\n\nprint(\"submission.csv generated successfully\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:11:41.240963Z","iopub.status.idle":"2025-12-18T17:11:41.241234Z","shell.execute_reply.started":"2025-12-18T17:11:41.241109Z","shell.execute_reply":"2025-12-18T17:11:41.241124Z"}},"outputs":[],"execution_count":null}]}